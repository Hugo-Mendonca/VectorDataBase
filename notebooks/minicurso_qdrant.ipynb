{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f14da26",
   "metadata": {},
   "source": [
    "# Minicurso Prático: Vector Database com Qdrant\n",
    "\n",
    "Neste notebook, vamos aprender na prática como interagir com um banco de dados vetorial, o **Qdrant**. Cobriremos o ciclo completo de operações, desde a criação de uma \"coleção\" até a execução de buscas semânticas inteligentes.\n",
    "\n",
    "**O que vamos fazer:**\n",
    "1.  **Conectar** ao nosso banco de dados Qdrant rodando no Docker.\n",
    "2.  **Preparar um modelo de IA** para transformar texto em vetores (embeddings).\n",
    "3.  **Criar uma coleção** para armazenar nossos vetores.\n",
    "4.  **Inserir dados** (documentos de texto sobre IA, culinária, ciência e história).\n",
    "5.  **Realizar buscas** que entendem o significado, não apenas palavras-chave.\n",
    "6.  **Filtrar resultados** combinando busca semântica e metadados.\n",
    "7.  **Gerenciar os dados** com operações de deleção e contagem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c2fd6c",
   "metadata": {},
   "source": [
    "## Passo 1: Importando as Bibliotecas e Conectando ao Banco\n",
    "\n",
    "Vamos importar as bibliotecas necessárias para o nosso trabalho e estabelecer a conexão com a instância do Qdrant que está rodando no Docker.\n",
    "\n",
    "- `qdrant_client`: Lib para \"conversar\" com o Qdrant.\n",
    "- `sentence_transformers`: Lib que contém o modelo de IA para gerar os vetores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63e4f3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexão com o Qdrant estabelecida com sucesso!\n",
      "Versão do Qdrant: collections=[CollectionDescription(name='documentos_ia')]\n"
     ]
    }
   ],
   "source": [
    "# Importações\n",
    "from qdrant_client import QdrantClient, models\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np #importante para manipulação de vetores\n",
    "\n",
    "# --- Conexão com o Cliente Qdrant ---\n",
    "# Se o Qdrant está rodando via `docker-compose up`, ele estará acessível neste endereço.\n",
    "try:\n",
    "    client = QdrantClient(host=\"localhost\", port=6333)\n",
    "    print(\"Conexão com o Qdrant estabelecida com sucesso!\")\n",
    "    print(\"Versão do Qdrant:\", client.get_collections()) # teste para verificar se a conexão está funcionando\n",
    "except Exception as e:\n",
    "    print(f\"Falha ao conectar com o Qdrant. Verifique se o contêiner Docker está rodando.\")\n",
    "    print(f\"Erro: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b647fb",
   "metadata": {},
   "source": [
    "## Passo 2: Preparando o Modelo de IA e a Coleção\n",
    "\n",
    "Agora que estamos conectados, precisamos de duas coisas antes de inserir dados:\n",
    "\n",
    "1.  **Um modelo de IA:** Ele será nossa \"ferramenta\" para transformar textos (que o banco não entende) em vetores numéricos (que o banco entende). Usaremos um modelo pré-treinado da biblioteca `Sentence Transformers`.\n",
    "2.  **Uma \"coleção\" no Qdrant:** É o espaço, similar a uma tabela, onde nossos vetores e metadados serão armazenados.\n",
    "\n",
    "Vamos carregar o modelo e definir as configurações da nossa coleção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd7ac9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'SentenceTransformer' carregado.\n",
      "Tamanho do vetor (dimensionalidade): 384\n",
      "Nome da coleção que será criada: 'documentos_ia'\n"
     ]
    }
   ],
   "source": [
    "# Carrega o modelo pré-treinado 'all-MiniLM-L6-v2' da biblioteca SentenceTransformer.\n",
    "# Este modelo é leve e eficiente, ótimo para demonstrações. Ele é o responsável\n",
    "# por converter nossas frases em vetores.\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Precisamos saber o tamanho (a dimensionalidade) dos vetores que o modelo gera.\n",
    "# Para este modelo, o tamanho é 384.\n",
    "vector_size = model.get_sentence_embedding_dimension()\n",
    "\n",
    "# Por fim, definimos o nome da nossa coleção.\n",
    "collection_name = \"documentos_ia\"\n",
    "\n",
    "print(f\"Modelo '{model.__class__.__name__}' carregado.\")\n",
    "print(f\"Tamanho do vetor (dimensionalidade): {vector_size}\")\n",
    "print(f\"Nome da coleção que será criada: '{collection_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7390f502",
   "metadata": {},
   "source": [
    "Com as configurações prontas, vamos efetivamente criar a **coleção** no Qdrant.\n",
    "\n",
    "O código abaixo primeiro tenta deletar a coleção se ela já existir. Isso serve para que possamos rodar o notebook várias vezes desde o início sem receber um erro de \"coleção já existe\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a9de2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coleção 'documentos_ia' antiga encontrada e deletada para garantir um início limpo.\n",
      "Coleção 'documentos_ia' criada com sucesso no Qdrant!\n"
     ]
    }
   ],
   "source": [
    "#`try/except` para deletar a coleção se ela já existir\n",
    "try:\n",
    "    client.delete_collection(collection_name=collection_name)\n",
    "    print(f\"Coleção '{collection_name}' antiga encontrada e deletada para garantir um início limpo.\")\n",
    "except Exception as e:\n",
    "    print(f\"Coleção '{collection_name}' não existia previamente. Tudo certo para continuar.\")\n",
    "\n",
    "# Cria a nova coleção com a configuração de vetores que definimos\n",
    "client.create_collection(\n",
    "    collection_name=collection_name, #documentos_ia\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=vector_size,      # o tamanho do vetor (384)\n",
    "        distance=models.Distance.COSINE  # a métrica de similaridade de cosseno\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(f\"Coleção '{collection_name}' criada com sucesso no Qdrant!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b3fe0e",
   "metadata": {},
   "source": [
    "## Passo 3: Inserindo Dados na Coleção\n",
    "\n",
    "Com a nossa coleção vazia criada, vamos agora para etapa de 'escrita' no banco de dados. Vamos pegar uma lista de frases simples, com temas variados, e prepará-las para serem inseridas.\n",
    "\n",
    "Cada 'item' que inserimos no Qdrant é chamado de **ponto** (Point). Um `ponto` é a estrutura fundamental e é composto por 3 partes principais:\n",
    "- `id`: Um identificador único para o ponto (como uma chave primária).\n",
    "- `vector`: O vetor numérico gerado pelo nosso modelo de IA. É a representação matemática do dado.\n",
    "- `payload`: Um dicionário com dados extras que queremos associar ao vetor (metadados), como o texto original, categorias, datas, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8e225f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temos 20 documentos de exemplo para inserir.\n"
     ]
    }
   ],
   "source": [
    "# Primeiro, definimos a nossa lista de documentos em um formato de dicionário Python.\n",
    "# Cada dicionário contém o texto a ser vetorizado e uma categoria como metadado.\n",
    "documents = [\n",
    "    # Tecnologia\n",
    "    {\"text\": \"A inteligência artificial está revolucionando a medicina com diagnósticos mais precisos.\", \"category\": \"tecnologia\"},\n",
    "    {\"text\": \"Grandes modelos de linguagem (LLMs) são a base de muitos chatbots e assistentes virtuais.\", \"category\": \"tecnologia\"},\n",
    "    {\"text\": \"O aprendizado de máquina é um subcampo da IA focado em algoritmos que aprendem com dados.\", \"category\": \"tecnologia\"},\n",
    "    {\"text\": \"A computação em nuvem permite o armazenamento e processamento de dados em larga escala.\", \"category\": \"tecnologia\"},\n",
    "    {\"text\": \"Cibersegurança é a prática de proteger sistemas e redes contra ataques digitais.\", \"category\": \"tecnologia\"},\n",
    "\n",
    "    # Culinária\n",
    "    {\"text\": \"A culinária italiana é famosa por suas massas frescas e pizzas de forno a lenha.\", \"category\": \"culinaria\"},\n",
    "    {\"text\": \"O sushi é um prato tradicional japonês feito de arroz temperado, peixe cru e algas.\", \"category\": \"culinaria\"},\n",
    "    {\"text\": \"A moqueca capixaba é um cozido de peixe e frutos do mar típico do Espírito Santo, Brasil.\", \"category\": \"culinaria\"},\n",
    "    {\"text\": \"Os croissants franceses são conhecidos por sua massa folhada crocante e amanteigada.\", \"category\": \"culinaria\"},\n",
    "    {\"text\": \"Cozinhar sous-vide é uma técnica que utiliza um banho de água a temperatura controlada.\", \"category\": \"culinaria\"},\n",
    "\n",
    "    # História\n",
    "    {\"text\": \"O Império Romano foi uma das civilizações mais influentes da história ocidental.\", \"category\": \"historia\"},\n",
    "    {\"text\": \"A Segunda Guerra Mundial foi um conflito global que durou de 1939 a 1945.\", \"category\": \"historia\"},\n",
    "    {\"text\": \"Cleópatra foi a última faraó do Antigo Egito, conhecida por sua inteligência e alianças políticas.\", \"category\": \"historia\"},\n",
    "    {\"text\": \"A Proclamação da República no Brasil ocorreu em 15 de novembro de 1889.\", \"category\": \"historia\"},\n",
    "    {\"text\": \"As pirâmides de Gizé serviram como tumbas para os faraós Quéops, Quéfren e Miquerinos.\", \"category\": \"historia\"},\n",
    "\n",
    "    # Ciência\n",
    "    {\"text\": \"A teoria da relatividade de Albert Einstein mudou nossa compreensão sobre espaço e tempo.\", \"category\": \"ciencia\"},\n",
    "    {\"text\": \"O telescópio espacial James Webb consegue observar galáxias formadas logo após o Big Bang.\", \"category\": \"ciencia\"},\n",
    "    {\"text\": \"A molécula de DNA contém as instruções genéticas para o desenvolvimento dos seres vivos.\", \"category\": \"ciencia\"},\n",
    "    {\"text\": \"A fotossíntese é o processo pelo qual as plantas convertem luz solar em energia química.\", \"category\": \"ciencia\"},\n",
    "    {\"text\": \"Buracos negros são regiões do espaço com um campo gravitacional extremamente forte.\", \"category\": \"ciencia\"},\n",
    "]\n",
    "\n",
    "print(f\"Temos {len(documents)} documentos de exemplo para inserir.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffac909",
   "metadata": {},
   "source": [
    "Agora, vamos iterar (fazer um loop) sobre cada documento da lista acima. Para cada um, faremos duas coisas:\n",
    "\n",
    "1.  **Gerar o Embedding:** Usar nosso modelo (`model`) para transformar o texto em um vetor de 384 dimensões.\n",
    "2.  **Criar o Ponto:** Montar a estrutura do `PointStruct` do Qdrant com o ID, o vetor gerado e o payload (nossos metadados)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be15121d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\55819\\Desktop\\projetos\\banco-de-dados\\seminario\\VectorDataBase\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estrutura de dados para 20 pontos foi criada com sucesso.\n",
      "\n",
      "Exemplo do primeiro ponto a ser inserido:\n",
      "id=0 vector=[-0.0058999331668019295, -0.009198222309350967, -0.04568072780966759, -0.0062173232436180115, -0.08498112857341766, -0.03501074016094208, 0.014892986975610256, 0.11612645536661148, 0.034215763211250305, 0.023821623995900154, 0.05144776031374931, 0.015415575355291367, -0.023634886369109154, -0.000549100514035672, -0.1196724995970726, -0.026842832565307617, 0.03396619111299515, 0.012623627670109272, 0.03486590087413788, 0.034491702914237976, 0.02379419468343258, -0.006574203725904226, -0.06870835274457932, 0.0774228572845459, -0.0926598459482193, 0.04005620628595352, 0.025128668174147606, -0.08153228461742401, -0.011863509193062782, -0.042686495929956436, 0.08866962045431137, 0.07166998833417892, 0.09888964146375656, -0.060623899102211, -0.0051544662564992905, -0.0407172366976738, 0.07826758176088333, -0.029718605801463127, 0.025781283155083656, 0.0735730230808258, -0.05651209503412247, -0.12534140050411224, -0.02797134965658188, -0.07290270179510117, 0.06745397299528122, -0.04117117449641228, -0.06686395406723022, 0.06541333347558975, 0.01933266408741474, 0.016505304723978043, -0.11962646245956421, -0.04605426639318466, -0.02572501078248024, 0.03215588256716728, -0.013478809967637062, -0.007520837709307671, 0.08869574964046478, -0.06342477351427078, -0.08540771156549454, 0.07702285051345825, 0.031000353395938873, 0.03870910033583641, 0.0021950528025627136, 0.04439042881131172, 0.06006336212158203, 0.09122896939516068, 0.01830817386507988, -0.035095732659101486, 0.047684021294116974, -0.022252850234508514, 0.051014143973588943, -0.015943022444844246, 0.05227133259177208, 0.09798428416252136, 0.033445559442043304, -0.002065118867903948, -0.011444454081356525, 0.048831112682819366, 0.05342140048742294, -0.028594933450222015, -0.014395096339285374, 0.003888503648340702, -0.011662188917398453, 0.03276143968105316, 0.05133833363652229, 0.02631961554288864, -0.07293388992547989, -0.0009827478788793087, 0.043857354670763016, 0.0005677148583345115, 0.0593242384493351, -0.030920177698135376, -0.06905701756477356, -0.0020250186789780855, 0.06806879490613937, 0.020463986322283745, 0.014750801026821136, -0.09331586956977844, 0.10028041154146194, 0.01864207163453102, -0.010359581559896469, -0.02214992791414261, -0.07300788909196854, 0.027901876717805862, -0.05413554981350899, -0.003923383541405201, 0.06069782003760338, -0.0884706899523735, 0.07707002013921738, 0.001313438406214118, -0.07694875448942184, -0.031888674944639206, -0.030133476480841637, -0.07937943190336227, -0.04926667362451553, 0.0055930656380951405, 0.05452021211385727, 0.07347408682107925, 0.015667356550693512, -0.0876806303858757, 0.041681136935949326, -0.01921355351805687, 0.0009470923105254769, -0.09591580927371979, 0.16091471910476685, -0.005698846653103828, -0.013525392860174179, 1.436710868752093e-33, -0.037461765110492706, 0.03987494483590126, 0.026414377614855766, 0.03793133422732353, -0.038511183112859726, 0.009136143140494823, -0.06592177599668503, -0.057681065052747726, 0.06104044243693352, -0.017570970579981804, -0.04823815077543259, 0.034180767834186554, -0.06110706925392151, 0.011981374584138393, 0.03483596816658974, 0.035870157182216644, 0.007581579964607954, 0.0225271787494421, -0.001998580526560545, -0.008595992811024189, -0.02235398069024086, -0.10135117173194885, 0.033801354467868805, -0.04220196604728699, -0.037322744727134705, 0.10219401121139526, -0.005757538136094809, 0.024091796949505806, 0.0004749942454509437, 0.03220207989215851, 0.01336331944912672, 0.00610739178955555, -0.0356755368411541, -0.028833113610744476, -0.03581506758928299, 0.01965228281915188, 0.05987394228577614, 0.019906016066670418, 0.04201601445674896, 0.08877880871295929, 0.04030675068497658, 0.014385445974767208, 0.0479239895939827, 0.018389269709587097, 0.06822126358747482, 0.002092683454975486, -0.05999971926212311, -0.01234643068164587, 0.07210765779018402, -0.022045832127332687, -0.10224787145853043, -0.041912954300642014, -0.0033101877197623253, -0.051970768719911575, 0.05165986344218254, 0.05999237671494484, -0.0897359549999237, 0.041034769266843796, 0.0031262882985174656, -0.06249501556158066, 0.01443464308977127, 0.02773471362888813, -0.03332215175032616, 0.04169052094221115, -0.06563512235879898, -0.018322162330150604, 0.01178270298987627, -0.03051154315471649, 0.11506514996290207, 0.04239065572619438, -0.08134834468364716, 0.009021545760333538, -0.028800494968891144, 0.05926564335823059, -0.04129069671034813, -0.034768424928188324, -0.02225758507847786, -0.018982548266649246, 0.005699323955923319, -0.006901227869093418, -0.03402458503842354, 0.025508593767881393, 0.018673036247491837, 0.06800400465726852, 0.11944618076086044, 0.07606817036867142, -0.03382948786020279, 0.08092794567346573, -0.0001785413478501141, -0.012762554921209812, 0.0007144412375055254, 0.06429429352283478, -0.0014229731168597937, 0.034220464527606964, 0.03266015276312828, -4.7278529726866256e-33, -0.0528997965157032, -0.012913739308714867, -0.04430040717124939, 0.04298674687743187, 0.040486838668584824, -0.04326127842068672, -0.012998194433748722, 0.0025684963911771774, -0.004345792345702648, -0.004601695574820042, 0.004730657674372196, -0.07827352732419968, -0.025656895712018013, -0.014965010806918144, -0.041830554604530334, 0.11418107897043228, -0.06533578783273697, -0.08211564272642136, -0.03183932974934578, 0.012075304053723812, -0.054069213569164276, 0.04735526815056801, -0.026738842949271202, -0.08269858360290527, 0.012891286052763462, 0.001097765052691102, -0.005840301048010588, 0.040505170822143555, 0.024429382756352425, -0.026672238484025, -0.013547280803322792, -0.04437004774808884, -0.03857192024588585, 0.052410464733839035, -0.008510114625096321, 0.06656254827976227, 0.016263021156191826, -0.00809237640351057, -0.0029372384306043386, 0.018218036741018295, 0.00704311765730381, 0.04578619822859764, -0.033709216862916946, -0.08112361282110214, -0.017974145710468292, -0.018352897837758064, 0.009894507005810738, -0.05039634183049202, 0.052159570157527924, -0.002412869594991207, 0.06304187327623367, -0.03982354328036308, -0.05655049532651901, 0.00782980676740408, -0.005481624975800514, -0.08703041076660156, 0.004330434836447239, -0.05888506397604942, -0.06879833340644836, 0.06656704843044281, 0.05176319181919098, -0.001757944468408823, -0.043397579342126846, -0.022006606683135033, -0.043580785393714905, 0.01746169477701187, 0.03149247169494629, 0.0699867531657219, 0.020416609942913055, 0.004088225308805704, 0.0962248221039772, -0.03101172484457493, -0.07069717347621918, -0.009044130332767963, 0.026894589886069298, -0.03897881507873535, -0.15555055439472198, -0.005138646345585585, -0.03278501704335213, 0.019712377339601517, -0.00040804935269989073, -0.10059577971696854, 0.023510094732046127, -0.043528467416763306, -0.05147735774517059, -0.02767224982380867, -0.04564271494746208, -0.018125079572200775, -0.04655833914875984, 0.01048353686928749, -0.010714412666857243, 0.02482626959681511, -0.08503672480583191, -0.04040021821856499, -0.057784393429756165, -3.053146357956393e-08, 0.005190532188862562, -0.0806092843413353, 0.09906972944736481, -0.03469325602054596, 0.014085090719163418, -0.10388005524873734, -0.030750218778848648, 0.0005163224413990974, -0.005483980290591717, -0.036457814276218414, -0.08878391981124878, 0.003363130846992135, 0.010246708989143372, 0.011398108676075935, 0.022042129188776016, -0.00044431679998524487, 0.03653249517083168, 0.12204133719205856, -0.05760011821985245, -0.04639690741896629, 0.12085490673780441, -0.02910001575946808, -0.071555957198143, -0.09410534799098969, 0.023122655227780342, 0.014843244105577469, -0.02547808177769184, -0.012651718221604824, -0.05170844867825508, 0.03395373001694679, -0.0062829265370965, 0.04519609734416008, 0.009623858146369457, -0.01925041526556015, -0.010538244619965553, 0.03541292995214462, 0.01850472390651703, -0.021294796839356422, -0.027392277494072914, -0.044705577194690704, 0.029903395101428032, 0.013621880672872066, -0.05079187452793121, 0.010402778163552284, 0.020403971895575523, -0.10388131439685822, 0.034385934472084045, -0.029734062030911446, 0.07430239021778107, -0.004359123762696981, 0.0533907376229763, -0.03198240324854851, 0.08639364689588547, 0.010452364571392536, 0.02748258411884308, 0.020947836339473724, 0.11727743595838547, 0.01696128398180008, -0.10355114191770554, 0.02267705835402012, 0.0801529511809349, 0.015787729993462563, 0.08217650651931763, -0.13029591739177704] payload={'original_text': 'A inteligência artificial está revolucionando a medicina com diagnósticos mais precisos.', 'category': 'tecnologia'}\n"
     ]
    }
   ],
   "source": [
    "# Inicializamos uma lista vazia para guardar nossos pontos\n",
    "points = []\n",
    "\n",
    "# Loop para percorrer os documentos e transformá-los em pontos\n",
    "for idx, doc in enumerate(documents):\n",
    "    # Gerar o embedding: pega o texto e o transforma em um vetor numérico.\n",
    "    embedding = model.encode(doc[\"text\"]).tolist()\n",
    "    \n",
    "    # Cria a estrutura do ponto com ID, vetor e metadados (payload).\n",
    "    points.append(\n",
    "        models.PointStruct(\n",
    "            id=idx,  # Usamos o índice do loop como um ID único\n",
    "            vector=embedding,\n",
    "            payload={\n",
    "                \"original_text\": doc[\"text\"],\n",
    "                \"category\": doc[\"category\"]\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Ao final do loop, a lista 'points' conterá todos os nossos dados prontos para serem enviados.\n",
    "print(f\"Estrutura de dados para {len(points)} pontos foi criada com sucesso.\")\n",
    "print(\"\\nExemplo do primeiro ponto a ser inserido:\")\n",
    "print(points[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd35402",
   "metadata": {},
   "source": [
    "Com nossa lista de pontos pronta, usamos um único comando, `upsert`, para enviar todos eles para o Qdrant de uma vez. O comando `upsert` é bom porque ele insere novos pontos ou atualiza os que já existem (caso o ID já esteja no banco)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bff7a0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados inseridos no Qdrant!\n",
      "\n",
      "Informação da operação retornada pelo servidor:\n",
      "operation_id=0 status=<UpdateStatus.COMPLETED: 'completed'>\n"
     ]
    }
   ],
   "source": [
    "# Envia a lista de pontos para a nossa coleção no Qdrant.\n",
    "operation_info = client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    wait=True,  # Pede para a operação esperar a conclusão antes de continuar\n",
    "    points=points,\n",
    ")\n",
    "\n",
    "print(\"Dados inseridos no Qdrant!\")\n",
    "print(\"\\nInformação da operação retornada pelo servidor:\")\n",
    "print(operation_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a395a267",
   "metadata": {},
   "source": [
    "## Passo 4: Realizando Buscas Semânticas\n",
    "\n",
    "Com nossos dados no banco, é hora de consultá-los. Diferente de uma busca tradicional em SQL com `SELECT abc FROM xyz`, uma busca vetorial encontra os resultados mais \"próximos\" em significado.\n",
    "\n",
    "O processo é simples:\n",
    "1.  Definimos uma frase de busca (nossa \"pergunta\").\n",
    "2.  Usamos o **mesmo modelo de IA** para converter essa frase em um vetor.\n",
    "3.  Enviamos esse vetor para o Qdrant.\n",
    "4.  O Qdrant calcula a \"distância\" (usando a métrica de cosseno que definimos) entre o nosso vetor de busca e todos os vetores da coleção e nos retorna os mais próximos, ou seja, os mais similares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e6034b",
   "metadata": {},
   "source": [
    "### 4.1. Exemplo 1: Busca Semântica Pura\n",
    "\n",
    "Vamos começar com uma busca sobre **\"modelos de IA para conversação\"**. A palavra \"chatbot\", por exemplo, não está na nossa frase de busca, mas está em um dos documentos que inserimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dc618bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resultados da busca por: 'modelos de IA para conversação' ---\n",
      "\n",
      "ID do Ponto: 1\n",
      "Similaridade (Score): 0.4952\n",
      "  Texto Original: Grandes modelos de linguagem (LLMs) são a base de muitos chatbots e assistentes virtuais.\n",
      "  Categoria: tecnologia\n",
      "\n",
      "ID do Ponto: 3\n",
      "Similaridade (Score): 0.4240\n",
      "  Texto Original: A computação em nuvem permite o armazenamento e processamento de dados em larga escala.\n",
      "  Categoria: tecnologia\n",
      "\n",
      "ID do Ponto: 4\n",
      "Similaridade (Score): 0.4093\n",
      "  Texto Original: Cibersegurança é a prática de proteger sistemas e redes contra ataques digitais.\n",
      "  Categoria: tecnologia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\55819\\AppData\\Local\\Temp\\ipykernel_11228\\363025758.py:8: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_result_1 = client.search(\n"
     ]
    }
   ],
   "source": [
    "# 1. Definimos a nossa busca\n",
    "query_text_1 = \"modelos de IA para conversação\"\n",
    "\n",
    "# 2. Convertemos a busca em um vetor\n",
    "query_embedding_1 = model.encode(query_text_1).tolist()\n",
    "\n",
    "# 3. Executamos a busca no Qdrant\n",
    "search_result_1 = client.search(\n",
    "    collection_name=collection_name,\n",
    "    query_vector=query_embedding_1,\n",
    "    limit=3,  # pedimos os 3 resultados mais próximos\n",
    "    with_payload=True  # dizemos para incluir os metadados\n",
    ")\n",
    "\n",
    "# 4. Exibimos os resultados de forma legível\n",
    "print(f\"--- Resultados da busca por: '{query_text_1}' ---\")\n",
    "for hit in search_result_1:\n",
    "    print(f\"\\nID do Ponto: {hit.id}\")\n",
    "    print(f\"Similaridade (Score): {hit.score:.4f}\")\n",
    "    print(f\"  Texto Original: {hit.payload['original_text']}\")\n",
    "    print(f\"  Categoria: {hit.payload['category']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19254e31",
   "metadata": {},
   "source": [
    "### 4.2. Exemplo 2: Combinando Busca Semântica com Filtros\n",
    "\n",
    "Esta é uma das funcionalidades mais úteis dos bancos de dados vetoriais modernos. E se quisermos encontrar textos sobre um assunto, mas apenas dentro de uma **categoria específica**?\n",
    "\n",
    "Vamos buscar por **\"comida boa\"**, mas restringindo a busca **apenas** para os documentos da categoria `culinaria`. Isso evita que o resultado traga, por exemplo, um texto sobre a \"boa\" estratégia de um imperador romano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78a99cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resultados da busca por: 'comida boa' (filtrado por Categoria: culinaria) ---\n",
      "\n",
      "ID do Ponto: 7\n",
      "Similaridade (Score): 0.3236\n",
      "  Texto Original: A moqueca capixaba é um cozido de peixe e frutos do mar típico do Espírito Santo, Brasil.\n",
      "  Categoria: culinaria\n",
      "\n",
      "ID do Ponto: 5\n",
      "Similaridade (Score): 0.2892\n",
      "  Texto Original: A culinária italiana é famosa por suas massas frescas e pizzas de forno a lenha.\n",
      "  Categoria: culinaria\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\55819\\AppData\\Local\\Temp\\ipykernel_11228\\1328935485.py:8: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_result_2 = client.search(\n"
     ]
    }
   ],
   "source": [
    "# 1. Definimos a nova busca\n",
    "query_text_2 = \"comida boa\"\n",
    "\n",
    "# 2. Convertemos em um vetor\n",
    "query_embedding_2 = model.encode(query_text_2).tolist()\n",
    "\n",
    "# 3. Executamos a busca, mas desta vez adicionando um filtro\n",
    "search_result_2 = client.search(\n",
    "    collection_name=collection_name,\n",
    "    query_vector=query_embedding_2,\n",
    "    # AQUI ESTÁ O FILTRO: definimos uma condição obrigatória (must)\n",
    "    # onde o campo 'category' no payload deve ter o valor 'culinaria'.\n",
    "    query_filter=models.Filter(\n",
    "        must=[\n",
    "            models.FieldCondition(\n",
    "                key=\"category\",\n",
    "                match=models.MatchValue(value=\"culinaria\")\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    limit=2, # Pedimos os 2 melhores resultados dentro do filtro\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "# 4. Exibimos os resultados\n",
    "print(f\"--- Resultados da busca por: '{query_text_2}' (filtrado por Categoria: culinaria) ---\")\n",
    "for hit in search_result_2:\n",
    "    print(f\"\\nID do Ponto: {hit.id}\")\n",
    "    print(f\"Similaridade (Score): {hit.score:.4f}\")\n",
    "    print(f\"  Texto Original: {hit.payload['original_text']}\")\n",
    "    print(f\"  Categoria: {hit.payload['category']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466e1364",
   "metadata": {},
   "source": [
    "## Passo 5: Gerenciando os Dados (Retrieve, Delete e Count)\n",
    "\n",
    "Além de buscar por similaridade, que é a função principal, podemos também realizar operações diretas nos dados. Por exemplo:\n",
    "- Buscar um item que já conhecemos pelo seu ID.\n",
    "- Remover dados que não são mais necessários ou estão desatualizados.\n",
    "- Verificar quantos itens temos no total."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82db8038",
   "metadata": {},
   "source": [
    "### 5.1. Buscando um Ponto Específico por ID (`retrieve`)\n",
    "\n",
    "Imagine que você já sabe o ID de um documento e quer apenas os dados dele, sem fazer uma busca por similaridade. Para isso, usamos o comando `retrieve`, que é extremamente rápido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e13fa31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado:\n",
      "[Record(id=2, payload={'original_text': 'O aprendizado de máquina é um subcampo da IA focado em algoritmos que aprendem com dados.', 'category': 'tecnologia'}, vector=None, shard_key=None, order_value=None)]\n"
     ]
    }
   ],
   "source": [
    "# Vamos buscar o ponto que tem o ID 2\n",
    "point_id_to_retrieve = 2\n",
    "\n",
    "retrieved_points = client.retrieve(\n",
    "    collection_name=collection_name,\n",
    "    ids=[point_id_to_retrieve],\n",
    "    with_payload=True # incluir os metadados\n",
    ")\n",
    "\n",
    "print(\"Resultado:\")\n",
    "print(retrieved_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db335aa5",
   "metadata": {},
   "source": [
    "### 5.2. Deletando Pontos da Coleção (`delete`)\n",
    "\n",
    "Agora, vamos simular a remoção de alguns dados. A operação `delete` permite remover um ou mais pontos de forma eficiente, bastando fornecer seus IDs. Vamos deletar os pontos com ID 3 e 4 (os de culinária)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef228e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Deletando os pontos com ID 3 e 4 ---\n",
      "Operação de deleção concluída!\n",
      "operation_id=1 status=<UpdateStatus.COMPLETED: 'completed'>\n"
     ]
    }
   ],
   "source": [
    "# Deleta os pontos com IDs 3 e 4 da nossa coleção.\n",
    "operation_info_delete = client.delete(\n",
    "    collection_name=collection_name,\n",
    "    points_selector=models.PointIdsList(points=[3, 4])\n",
    ")\n",
    "\n",
    "print(\"--- Deletando os pontos com ID 3 e 4 ---\")\n",
    "print(\"Operação de deleção concluída!\")\n",
    "print(operation_info_delete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b905cf1f",
   "metadata": {},
   "source": [
    "### 5.3. Verificando o Estado Final da Coleção (`count`)\n",
    "\n",
    "Depois de deletar podemos confirmar que a operação funcionou usando o comando `count` para ver quantos pontos restaram na coleção. Começamos com 20, deletamos 2, então o resultado deve ser 18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8747eacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Contando o total de pontos restantes ---\n",
      "Total de pontos na coleção 'documentos_ia': 18\n"
     ]
    }
   ],
   "source": [
    "# Conta o número de pontos restantes na coleção\n",
    "count_result = client.count(\n",
    "    collection_name=collection_name,\n",
    "    exact=True # Pede uma contagem exata\n",
    ")\n",
    "\n",
    "print(\"--- Contando o total de pontos restantes ---\")\n",
    "print(f\"Total de pontos na coleção '{collection_name}': {count_result.count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ceebff",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Completamos o ciclo de vida de interação com um banco de dados vetorial. Agora sabemos como:\n",
    "- **Configurar e conectar** a um banco de dados vetorial.\n",
    "- **Criar uma coleção** para armazenar vetores.\n",
    "- **Inserir dados** usando embeddings.\n",
    "- **Realizar buscas** semânticas e com filtros.\n",
    "- **Gerenciar os dados** com operações de busca por ID, deleção e contagem.\n",
    "\n",
    "### Caso de Uso Final\n",
    "\n",
    "Criamos uma aplicação web interativa simples com Streamlit (`src/app.py`). Vamos focar em usar a operação de `search` para criar uma experiência de busca.\n",
    "\n",
    "Teste no terminal: **streamlit run src/app.py**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
