{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f14da26",
   "metadata": {},
   "source": [
    "# Minicurso Prático: Vector Database com Qdrant\n",
    "\n",
    "Bem-vindo(a) à parte prática do nosso seminário!\n",
    "\n",
    "Neste notebook, vamos aprender na prática como interagir com um banco de dados vetorial, o **Qdrant**. Cobriremos o ciclo completo de operações, desde a criação de uma \"coleção\" até a execução de buscas semânticas inteligentes.\n",
    "\n",
    "**O que vamos fazer:**\n",
    "1.  **Conectar** ao nosso banco de dados Qdrant rodando no Docker.\n",
    "2.  **Preparar um modelo de IA** para transformar texto em vetores (embeddings).\n",
    "3.  **Criar uma coleção** para armazenar nossos vetores.\n",
    "4.  **Inserir dados** (documentos de texto sobre IA, culinária e história).\n",
    "5.  **Realizar buscas** que entendem o significado, não apenas palavras-chave.\n",
    "6.  **Filtrar resultados** combinando busca semântica e metadados.\n",
    "7.  **Gerenciar os dados** com operações de deleção e contagem.\n",
    "\n",
    "Vamos começar!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c2fd6c",
   "metadata": {},
   "source": [
    "## Passo 1: Importando as Bibliotecas e Conectando ao Banco\n",
    "\n",
    "Tudo começa aqui. Vamos importar as bibliotecas necessárias para o nosso trabalho e estabelecer a conexão com a instância do Qdrant que está rodando no Docker.\n",
    "\n",
    "- `qdrant_client`: A biblioteca oficial para \"conversar\" com o Qdrant.\n",
    "- `sentence_transformers`: A biblioteca que contém o nosso modelo de IA para gerar os vetores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63e4f3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexão com o Qdrant estabelecida com sucesso!\n",
      "Versão do Qdrant: collections=[]\n"
     ]
    }
   ],
   "source": [
    "# Importações principais\n",
    "from qdrant_client import QdrantClient, models\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np # É uma boa prática importar, pois é muito usado em operações com vetores\n",
    "\n",
    "# --- Conexão com o Cliente Qdrant ---\n",
    "# Se o Qdrant está rodando via `docker-compose up`, ele estará acessível neste endereço.\n",
    "try:\n",
    "    client = QdrantClient(host=\"localhost\", port=6333)\n",
    "    print(\"✅ Conexão com o Qdrant estabelecida com sucesso!\")\n",
    "    print(\"Versão do Qdrant:\", client.get_collections()) # Um pequeno teste para verificar a conexão\n",
    "except Exception as e:\n",
    "    print(f\"❌ Falha ao conectar com o Qdrant. Verifique se o contêiner Docker está rodando.\")\n",
    "    print(f\"Erro: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b647fb",
   "metadata": {},
   "source": [
    "## Passo 2: Preparando o Modelo de IA e a Coleção\n",
    "\n",
    "Agora que estamos conectados, precisamos de duas coisas antes de inserir dados:\n",
    "\n",
    "1.  **Um modelo de IA:** Ele será nossa \"ferramenta\" para transformar textos (que o banco não entende) em vetores numéricos (que o banco entende). Usaremos um modelo pré-treinado da biblioteca `Sentence Transformers`.\n",
    "2.  **Uma \"coleção\" no Qdrant:** É o espaço, similar a uma tabela, onde nossos vetores e metadados serão armazenados.\n",
    "\n",
    "Vamos carregar o modelo e definir as configurações da nossa coleção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd7ac9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'SentenceTransformer' carregado.\n",
      "Tamanho do vetor (dimensionalidade): 384\n",
      "Nome da coleção que será criada: 'documentos_ia'\n"
     ]
    }
   ],
   "source": [
    "# Carrega o modelo pré-treinado 'all-MiniLM-L6-v2' da biblioteca SentenceTransformer.\n",
    "# Este modelo é leve e eficiente, ótimo para demonstrações. Ele é o responsável\n",
    "# por converter nossas frases em vetores.\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Precisamos saber o tamanho (a dimensionalidade) dos vetores que o modelo gera.\n",
    "# Para este modelo, o tamanho é 384.\n",
    "vector_size = model.get_sentence_embedding_dimension()\n",
    "\n",
    "# Por fim, definimos o nome da nossa coleção.\n",
    "collection_name = \"documentos_ia\"\n",
    "\n",
    "print(f\"Modelo '{model.__class__.__name__}' carregado.\")\n",
    "print(f\"Tamanho do vetor (dimensionalidade): {vector_size}\")\n",
    "print(f\"Nome da coleção que será criada: '{collection_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7390f502",
   "metadata": {},
   "source": [
    "Com as configurações prontas, vamos efetivamente criar a coleção no Qdrant.\n",
    "\n",
    "**Importante:** O código abaixo primeiro tenta deletar a coleção se ela já existir. Fazemos isso para que, durante o minicurso, possamos rodar o notebook várias vezes desde o início sem receber um erro de \"coleção já existe\". É uma prática comum em notebooks de demonstração para garantir um ambiente limpo a cada execução."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a9de2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ Coleção 'documentos_ia' antiga encontrada e deletada para garantir um início limpo.\n",
      "✅ Coleção 'documentos_ia' criada com sucesso no Qdrant!\n"
     ]
    }
   ],
   "source": [
    "# Bloco `try/except` para deletar a coleção se ela já existir\n",
    "try:\n",
    "    client.delete_collection(collection_name=collection_name)\n",
    "    print(f\"ℹ️ Coleção '{collection_name}' antiga encontrada e deletada para garantir um início limpo.\")\n",
    "except Exception as e:\n",
    "    print(f\"ℹ️ Coleção '{collection_name}' não existia previamente. Tudo certo para continuar.\")\n",
    "\n",
    "# Cria a nova coleção com a configuração de vetores que definimos\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=vector_size,      # O tamanho do vetor (384)\n",
    "        distance=models.Distance.COSINE  # A métrica de similaridade de cosseno\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(f\"✅ Coleção '{collection_name}' criada com sucesso no Qdrant!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b3fe0e",
   "metadata": {},
   "source": [
    "## Passo 3: Inserindo Dados na Coleção\n",
    "\n",
    "Com a nossa coleção vazia criada, esta é a etapa de 'escrita' no banco de dados. Vamos pegar uma lista de frases simples, com temas variados, e prepará-las para serem inseridas.\n",
    "\n",
    "Cada 'item' que inserimos no Qdrant é chamado de **ponto** (Point). Um `ponto` é a estrutura fundamental e é composto por 3 partes principais:\n",
    "- `id`: Um identificador único para o ponto (como uma chave primária).\n",
    "- `vector`: O vetor numérico gerado pelo nosso modelo de IA. É a representação matemática do dado.\n",
    "- `payload`: Um dicionário com dados extras que queremos associar ao vetor (metadados), como o texto original, categorias, datas, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8e225f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temos 7 documentos de exemplo para inserir.\n"
     ]
    }
   ],
   "source": [
    "# Primeiro, definimos a nossa lista de documentos em um formato de dicionário Python.\n",
    "# Cada dicionário contém o texto a ser vetorizado e uma categoria como metadado.\n",
    "documents = [\n",
    "    {\"text\": \"A inteligência artificial está revolucionando a medicina.\", \"category\": \"tecnologia\"},\n",
    "    {\"text\": \"Grandes modelos de linguagem (LLMs) são a base de muitos chatbots.\", \"category\": \"tecnologia\"},\n",
    "    {\"text\": \"O aprendizado de máquina é um subcampo da IA.\", \"category\": \"tecnologia\"},\n",
    "    {\"text\": \"A culinária italiana é famosa por suas massas e pizzas.\", \"category\": \"culinaria\"},\n",
    "    {\"text\": \"Receitas saudáveis com vegetais frescos e orgânicos.\", \"category\": \"culinaria\"},\n",
    "    {\"text\": \"Explorando a história da Roma Antiga e seus imperadores.\", \"category\": \"historia\"},\n",
    "    {\"text\": \"Tutankhamon foi um faraó egípcio.\", \"category\": \"historia\"},\n",
    "]\n",
    "\n",
    "print(f\"Temos {len(documents)} documentos de exemplo para inserir.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffac909",
   "metadata": {},
   "source": [
    "Agora, vamos iterar (fazer um loop) sobre cada documento da lista acima. Para cada um, faremos duas coisas:\n",
    "\n",
    "1.  **Gerar o Embedding:** Usar nosso modelo (`model`) para transformar o texto em um vetor de 384 dimensões.\n",
    "2.  **Criar o Ponto:** Montar a estrutura do `PointStruct` do Qdrant com o ID, o vetor gerado e o payload (nossos metadados)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be15121d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estrutura de dados para 7 pontos foi criada com sucesso.\n",
      "\n",
      "Exemplo do primeiro ponto a ser inserido (para fins de visualização):\n",
      "id=0 vector=[-0.02474880963563919, 0.008848239667713642, -0.019703147932887077, -0.027849934995174408, -0.11648442596197128, -0.020190618932247162, 0.006632782053202391, 0.062217485159635544, 0.036311790347099304, 0.0348927266895771, 0.08233705163002014, 0.052650146186351776, -0.046630240976810455, -0.03433861956000328, -0.03502022475004196, 0.022223206236958504, 0.01072789542376995, 0.011419301852583885, 0.00830154214054346, 0.05925355851650238, 0.005376025568693876, -0.040512777864933014, -0.06499379873275757, 0.06454021483659744, -0.0726976990699768, 0.04193728417158127, 0.03962210193276405, -0.03631976246833801, 0.005612739361822605, -0.09428752958774567, 0.10018959641456604, 0.07958005368709564, 0.08315685391426086, -0.08576337993144989, -0.013789718970656395, -0.005622575059533119, 0.058065664023160934, -0.04129907488822937, 0.06081412360072136, 0.08969517052173615, -0.06503359973430634, -0.12954355776309967, -0.05607246235013008, -0.05518963932991028, 0.08459647744894028, -0.07152014225721359, -0.07483014464378357, 0.07576163113117218, 0.01874760165810585, 0.018444819375872612, -0.09998152405023575, -0.007290791254490614, -0.053576722741127014, 0.03690383955836296, 0.004460944794118404, -0.020935803651809692, 0.09986703097820282, -0.012483569793403149, -0.042729515582323074, 0.09873047471046448, 0.08769293129444122, 0.03215251863002777, -0.01827220618724823, 0.04045641049742699, 0.004331552889198065, 0.02745235711336136, 0.008405678905546665, -0.049621447920799255, 0.005098741967231035, -0.02400372363626957, 0.10004971921443939, -0.04866192117333412, 0.0075758155435323715, 0.07663846015930176, 0.026691092178225517, -0.05283511057496071, -0.019458750262856483, 0.02998201549053192, 0.05551407113671303, -0.008098773658275604, -0.02725369855761528, -0.01644456386566162, -0.03384365513920784, 0.033581092953681946, 0.025012632831931114, -0.02780623733997345, -0.09729411453008652, -0.01407674327492714, 0.11582324653863907, 0.02733791247010231, 0.01852269284427166, 0.017381416633725166, -0.031677987426519394, -0.04641446843743324, 0.0874725803732872, 0.025997240096330643, 0.001607396057806909, -0.10738956183195114, 0.05464109033346176, 0.04246092960238457, 0.028807638213038445, 0.013091188855469227, -0.11150477826595306, 0.026357881724834442, -0.0316845066845417, 0.028014283627271652, 0.07631047815084457, -0.045262660831213, 0.05409999564290047, 0.02958718128502369, -0.09965504705905914, -0.06114695966243744, -0.029506143182516098, -0.019261477515101433, -0.06147240474820137, 0.04161173850297928, 0.07038255780935287, 0.05377080291509628, 0.01187062542885542, -0.09682735055685043, 0.02136377990245819, 0.016897648572921753, -0.02131889946758747, -0.08155599236488342, 0.0807175412774086, -0.011805951595306396, 0.011353791691362858, -2.2884448716701444e-33, -0.0441519170999527, 0.053925588726997375, 0.007740494329482317, 0.027682270854711533, -0.029488764703273773, -0.00941731221973896, -0.03824251890182495, -0.05633450672030449, 0.007562614046037197, -0.048996880650520325, -0.03995497524738312, 0.021530816331505775, -0.07078868895769119, 0.049673233181238174, 0.06534755229949951, -0.020986424759030342, -0.05651020258665085, 0.02721555158495903, 0.04432177543640137, 0.017128905281424522, 0.024793561547994614, -0.07955500483512878, 0.023883815854787827, -0.05158521980047226, -0.046848364174366, 0.09138133376836777, 0.014204711653292179, 0.030725903809070587, -0.02708575315773487, 0.04455263540148735, 0.012786665931344032, 0.010935179889202118, -0.020910410210490227, -0.02212435193359852, -0.014838564209640026, 0.019590193405747414, 0.0452558696269989, 0.010409516282379627, 0.05112684890627861, 0.074738048017025, 0.011802001856267452, 0.05410236492753029, 0.07946565747261047, 0.012635448947548866, 0.049650974571704865, 0.038319434970617294, 0.014166840352118015, -0.006708379369229078, 0.1035633534193039, -0.01251303218305111, -0.1046702191233635, -0.02935255877673626, -0.015755541622638702, -0.09589922428131104, 0.0211995430290699, 0.032801635563373566, -0.10897114872932434, 0.08455371111631393, 0.0019743861630558968, -0.11296787858009338, 0.00920729897916317, 0.025226598605513573, -0.004542147275060415, 0.05929882824420929, -0.04148917645215988, 0.01012151688337326, -0.006939707323908806, -0.0037987329997122288, 0.1127566248178482, 0.003117038868367672, -0.05803518742322922, 0.005728131625801325, -0.02975202538073063, 0.057046324014663696, -0.06024101376533508, -0.020400837063789368, -0.0019131068838760257, -0.038497865200042725, 0.024209752678871155, -0.0008368705748580396, -0.051194578409194946, 0.02980910986661911, -0.03395552188158035, 0.05240826681256294, 0.1538378894329071, 0.09473223239183426, 0.03418319299817085, 0.03140425682067871, 0.030120661482214928, -0.00369006278924644, -0.0038410061970353127, 0.02491016685962677, 0.02251621149480343, 0.026722058653831482, 0.04431694746017456, -1.1095409443819991e-33, -0.05687389150261879, -0.036416199058294296, 0.005300510674715042, 0.05611228197813034, 0.06831113249063492, -0.02736653946340084, -0.033921219408512115, -0.010931058786809444, 0.002891951473429799, 0.03637374937534332, -0.028877293691039085, -0.08880743384361267, 0.039990104734897614, 0.01712772622704506, -0.02819094993174076, 0.04578413814306259, 0.004456806927919388, -0.09563850611448288, -0.05179363861680031, -0.00865907408297062, -0.05215800926089287, 0.032207898795604706, 0.014266067184507847, -0.007811679970473051, 0.04642865061759949, -0.0027403547428548336, -0.0589807890355587, 0.03328578919172287, 0.03608434647321701, -0.03632719814777374, -0.021564237773418427, -0.08544911444187164, -0.06018958240747452, 0.04809236899018288, -0.023212922737002373, 0.07695767283439636, 0.0023415328469127417, -0.010248849168419838, -0.004038115963339806, 0.020993132144212723, 0.007426480762660503, -0.02821194939315319, -0.040111836045980453, -0.017613988369703293, -0.011108615435659885, -0.004669771064072847, -0.01849319227039814, -0.055288925766944885, 0.0005108681507408619, -0.03720539063215256, 0.03994322940707207, -0.02194276824593544, -0.05176850035786629, 0.026438239961862564, 0.00773325189948082, -0.0886358991265297, 0.057159967720508575, -0.020120536908507347, -0.00704764761030674, 0.036598388105630875, 0.03922198712825775, 0.041012801229953766, -0.02663344331085682, -0.01578015275299549, -0.011571910232305527, -0.0007232929929159582, 0.008156043477356434, 0.02453613094985485, -0.013096500188112259, 0.017886845394968987, 0.13420319557189941, -0.03266441822052002, -0.06259631365537643, -0.007593704387545586, 0.0104321064427495, -0.04319443181157112, -0.115511454641819, -0.02459615282714367, -0.03970453515648842, -0.02154635824263096, -0.0005446765571832657, -0.06800855696201324, 0.01498411688953638, -0.06681584566831589, -0.030661748722195625, -0.02504907362163067, -0.04993290454149246, 0.0025171730667352676, -0.06551378220319748, 0.07388995587825775, -0.02597106620669365, 0.04354662820696831, -0.07864639908075333, -0.01685028336942196, -0.07397940754890442, -2.1761479729320854e-08, 0.008390533737838268, -0.026341190561652184, 0.10168725997209549, 0.02387133054435253, 0.007750792428851128, -0.11543672531843185, -0.05087311193346977, -0.02192198857665062, 0.01039948407560587, -0.05797377973794937, -0.052847933024168015, 0.04849531501531601, 0.06071421504020691, 0.028979629278182983, -0.005067446269094944, 0.04431456699967384, 0.07490429282188416, 0.1242251917719841, -0.03402905911207199, -0.050734248012304306, 0.07854706794023514, -0.017058856785297394, -0.05271623656153679, -0.1253032684326172, 0.006932109594345093, 0.04463721811771393, -0.053518109023571014, 0.001240698853507638, -0.016286352649331093, 0.03108787350356579, 0.01817256771028042, 0.03575681895017624, 0.011875729076564312, -0.029701976105570793, -0.037253670394420624, 0.010440850630402565, 0.0005332251312211156, -0.03134290128946304, -0.024323774501681328, -0.11016419529914856, 0.04021182656288147, 0.04533873498439789, -0.08686724305152893, 0.0038475662004202604, 0.02024807594716549, -0.08837433904409409, 0.005662107840180397, -0.02203499898314476, 0.04658028110861778, 0.026865750551223755, 0.037377528846263885, -0.0759025439620018, 0.08441391587257385, 0.0015579662285745144, 0.07397015392780304, 0.009975701570510864, 0.07066497206687927, -0.0007463650545105338, -0.0687401220202446, 0.005473889410495758, 0.054699499160051346, 0.020025519654154778, 0.09233347326517105, -0.14287590980529785] payload={'original_text': 'A inteligência artificial está revolucionando a medicina.', 'category': 'tecnologia'}\n"
     ]
    }
   ],
   "source": [
    "# Inicializamos uma lista vazia para guardar nossos pontos\n",
    "points = []\n",
    "\n",
    "# Loop para percorrer os documentos e transformá-los em pontos\n",
    "for idx, doc in enumerate(documents):\n",
    "    # Gerar o embedding: pega o texto e o transforma em um vetor numérico.\n",
    "    embedding = model.encode(doc[\"text\"]).tolist()\n",
    "    \n",
    "    # Cria a estrutura do ponto com ID, vetor e metadados (payload).\n",
    "    points.append(\n",
    "        models.PointStruct(\n",
    "            id=idx,  # Usamos o índice do loop como um ID único\n",
    "            vector=embedding,\n",
    "            payload={\n",
    "                \"original_text\": doc[\"text\"],\n",
    "                \"category\": doc[\"category\"]\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Ao final do loop, a lista 'points' conterá todos os nossos dados prontos para serem enviados.\n",
    "print(f\"Estrutura de dados para {len(points)} pontos foi criada com sucesso.\")\n",
    "print(\"\\nExemplo do primeiro ponto a ser inserido (para fins de visualização):\")\n",
    "print(points[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd35402",
   "metadata": {},
   "source": [
    "Com nossa lista de pontos pronta, usamos um único comando, `upsert`, para enviar todos eles para o Qdrant de uma vez. O comando `upsert` é eficiente pois ele insere novos pontos ou atualiza os que já existem (caso o ID já esteja no banco)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bff7a0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dados inseridos no Qdrant!\n",
      "\n",
      "Informação da operação retornada pelo servidor:\n",
      "operation_id=0 status=<UpdateStatus.COMPLETED: 'completed'>\n"
     ]
    }
   ],
   "source": [
    "# Envia a lista de pontos para a nossa coleção no Qdrant.\n",
    "operation_info = client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    wait=True,  # Pede para a operação esperar a conclusão antes de continuar\n",
    "    points=points,\n",
    ")\n",
    "\n",
    "print(\"✅ Dados inseridos no Qdrant!\")\n",
    "print(\"\\nInformação da operação retornada pelo servidor:\")\n",
    "print(operation_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a395a267",
   "metadata": {},
   "source": [
    "## Passo 4: Realizando Buscas Semânticas (CRUD - Read)\n",
    "\n",
    "Com nossos dados no banco, é hora de consultá-los. Diferente de uma busca tradicional em SQL com `WHERE texto LIKE '%palavra%'`, uma busca vetorial encontra os resultados mais \"próximos\" em significado.\n",
    "\n",
    "O processo é simples:\n",
    "1.  Definimos uma frase de busca (nossa \"pergunta\").\n",
    "2.  Usamos o **mesmo modelo de IA** para converter essa frase em um vetor.\n",
    "3.  Enviamos esse vetor para o Qdrant.\n",
    "4.  O Qdrant calcula a \"distância\" (usando a métrica de cosseno que definimos) entre o nosso vetor de busca e todos os vetores da coleção e nos retorna os mais próximos, ou seja, os mais similares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e6034b",
   "metadata": {},
   "source": [
    "### 4.1. Exemplo 1: Busca Semântica Pura\n",
    "\n",
    "Vamos começar com uma busca sobre **\"modelos de IA para conversação\"**. Note que a palavra \"chatbot\" não está na nossa frase de busca, mas está em um dos documentos que inserimos. Vamos ver se o Qdrant é inteligente o suficiente para entender essa conexão semântica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dc618bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resultados da busca por: 'modelos de IA para conversação' ---\n",
      "\n",
      "ID do Ponto: 1\n",
      "Similaridade (Score): 0.4922\n",
      "  Texto Original: Grandes modelos de linguagem (LLMs) são a base de muitos chatbots.\n",
      "  Categoria: tecnologia\n",
      "\n",
      "ID do Ponto: 2\n",
      "Similaridade (Score): 0.4148\n",
      "  Texto Original: O aprendizado de máquina é um subcampo da IA.\n",
      "  Categoria: tecnologia\n",
      "\n",
      "ID do Ponto: 0\n",
      "Similaridade (Score): 0.4068\n",
      "  Texto Original: A inteligência artificial está revolucionando a medicina.\n",
      "  Categoria: tecnologia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\55819\\AppData\\Local\\Temp\\ipykernel_101664\\3154319202.py:8: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_result_1 = client.search(\n"
     ]
    }
   ],
   "source": [
    "# 1. Definimos a nossa busca\n",
    "query_text_1 = \"modelos de IA para conversação\"\n",
    "\n",
    "# 2. Convertemos a busca em um vetor\n",
    "query_embedding_1 = model.encode(query_text_1).tolist()\n",
    "\n",
    "# 3. Executamos a busca no Qdrant\n",
    "search_result_1 = client.search(\n",
    "    collection_name=collection_name,\n",
    "    query_vector=query_embedding_1,\n",
    "    limit=3,  # Pedimos os 3 resultados mais próximos\n",
    "    with_payload=True  # Dizemos para incluir os metadados (nosso texto original e categoria)\n",
    ")\n",
    "\n",
    "# 4. Exibimos os resultados de forma legível\n",
    "print(f\"--- Resultados da busca por: '{query_text_1}' ---\")\n",
    "for hit in search_result_1:\n",
    "    print(f\"\\nID do Ponto: {hit.id}\")\n",
    "    print(f\"Similaridade (Score): {hit.score:.4f}\")\n",
    "    print(f\"  Texto Original: {hit.payload['original_text']}\")\n",
    "    print(f\"  Categoria: {hit.payload['category']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19254e31",
   "metadata": {},
   "source": [
    "### 4.2. Exemplo 2: Combinando Busca Semântica com Filtros\n",
    "\n",
    "Esta é uma das funcionalidades mais úteis dos bancos de dados vetoriais modernos. E se quisermos encontrar textos sobre um assunto, mas apenas dentro de uma **categoria específica**?\n",
    "\n",
    "Vamos buscar por **\"comida boa\"**, mas restringindo a busca **apenas** para os documentos da categoria `culinaria`. Isso evita que o resultado traga, por exemplo, um texto sobre a \"boa\" estratégia de um imperador romano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78a99cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resultados da busca por: 'comida boa' (filtrado por Categoria: culinaria) ---\n",
      "\n",
      "ID do Ponto: 4\n",
      "Similaridade (Score): 0.2985\n",
      "  Texto Original: Receitas saudáveis com vegetais frescos e orgânicos.\n",
      "  Categoria: culinaria\n",
      "\n",
      "ID do Ponto: 3\n",
      "Similaridade (Score): 0.2749\n",
      "  Texto Original: A culinária italiana é famosa por suas massas e pizzas.\n",
      "  Categoria: culinaria\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\55819\\AppData\\Local\\Temp\\ipykernel_101664\\1328935485.py:8: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_result_2 = client.search(\n"
     ]
    }
   ],
   "source": [
    "# 1. Definimos a nova busca\n",
    "query_text_2 = \"comida boa\"\n",
    "\n",
    "# 2. Convertemos em um vetor\n",
    "query_embedding_2 = model.encode(query_text_2).tolist()\n",
    "\n",
    "# 3. Executamos a busca, mas desta vez adicionando um filtro\n",
    "search_result_2 = client.search(\n",
    "    collection_name=collection_name,\n",
    "    query_vector=query_embedding_2,\n",
    "    # AQUI ESTÁ O FILTRO: definimos uma condição obrigatória (must)\n",
    "    # onde o campo 'category' no payload deve ter o valor 'culinaria'.\n",
    "    query_filter=models.Filter(\n",
    "        must=[\n",
    "            models.FieldCondition(\n",
    "                key=\"category\",\n",
    "                match=models.MatchValue(value=\"culinaria\")\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    limit=2, # Pedimos os 2 melhores resultados dentro do filtro\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "# 4. Exibimos os resultados\n",
    "print(f\"--- Resultados da busca por: '{query_text_2}' (filtrado por Categoria: culinaria) ---\")\n",
    "for hit in search_result_2:\n",
    "    print(f\"\\nID do Ponto: {hit.id}\")\n",
    "    print(f\"Similaridade (Score): {hit.score:.4f}\")\n",
    "    print(f\"  Texto Original: {hit.payload['original_text']}\")\n",
    "    print(f\"  Categoria: {hit.payload['category']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466e1364",
   "metadata": {},
   "source": [
    "## Passo 5: Gerenciando os Dados (Retrieve, Delete e Count)\n",
    "\n",
    "Além de buscar por similaridade, que é a função principal, muitas vezes precisamos realizar operações diretas nos dados. Por exemplo:\n",
    "- Buscar um item que já conhecemos pelo seu ID.\n",
    "- Remover dados que não são mais necessários ou estão desatualizados.\n",
    "- Verificar quantos itens temos no total."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82db8038",
   "metadata": {},
   "source": [
    "### 5.1. Buscando um Ponto Específico por ID (`retrieve`)\n",
    "\n",
    "Imagine que você já sabe o ID de um documento e quer apenas os dados dele, sem fazer uma busca por similaridade. Para isso, usamos o comando `retrieve`, que é extremamente rápido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e13fa31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Buscando o ponto com ID: 2 ---\n",
      "Resultado:\n",
      "[Record(id=2, payload={'original_text': 'O aprendizado de máquina é um subcampo da IA.', 'category': 'tecnologia'}, vector=None, shard_key=None, order_value=None)]\n"
     ]
    }
   ],
   "source": [
    "# Vamos buscar o ponto que tem o ID 2 (no nosso caso, sobre \"aprendizado de máquina\")\n",
    "point_id_to_retrieve = 2\n",
    "\n",
    "retrieved_points = client.retrieve(\n",
    "    collection_name=collection_name,\n",
    "    ids=[point_id_to_retrieve],\n",
    "    with_payload=True # Pedimos para incluir os metadados\n",
    ")\n",
    "\n",
    "print(f\"--- Buscando o ponto com ID: {point_id_to_retrieve} ---\")\n",
    "print(\"Resultado:\")\n",
    "print(retrieved_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db335aa5",
   "metadata": {},
   "source": [
    "### 5.2. Deletando Pontos da Coleção (`delete`)\n",
    "\n",
    "Agora, vamos simular a remoção de alguns dados. A operação `delete` permite remover um ou mais pontos de forma eficiente, bastando fornecer seus IDs. Vamos deletar os pontos com ID 3 e 4 (os de culinária)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef228e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Deletando os pontos com ID 3 e 4 ---\n",
      "Operação de deleção concluída!\n",
      "operation_id=1 status=<UpdateStatus.COMPLETED: 'completed'>\n"
     ]
    }
   ],
   "source": [
    "# Deleta os pontos com IDs 3 e 4 da nossa coleção.\n",
    "operation_info_delete = client.delete(\n",
    "    collection_name=collection_name,\n",
    "    points_selector=models.PointIdsList(points=[3, 4])\n",
    ")\n",
    "\n",
    "print(\"--- Deletando os pontos com ID 3 e 4 ---\")\n",
    "print(\"Operação de deleção concluída!\")\n",
    "print(operation_info_delete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b905cf1f",
   "metadata": {},
   "source": [
    "### 5.3. Verificando o Estado Final da Coleção (`count`)\n",
    "\n",
    "Depois de deletar, como podemos confirmar que a operação funcionou? Usamos o comando `count` para ver quantos pontos restaram na coleção. Começamos com 7, deletamos 2, então o resultado deve ser 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8747eacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Contando o total de pontos restantes ---\n",
      "Total de pontos na coleção 'documentos_ia': 5\n"
     ]
    }
   ],
   "source": [
    "# Conta o número de pontos restantes na coleção\n",
    "count_result = client.count(\n",
    "    collection_name=collection_name,\n",
    "    exact=True # Pede uma contagem exata\n",
    ")\n",
    "\n",
    "print(\"--- Contando o total de pontos restantes ---\")\n",
    "print(f\"Total de pontos na coleção '{collection_name}': {count_result.count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ceebff",
   "metadata": {},
   "source": [
    "## Conclusão do Notebook\n",
    "\n",
    "Você completou o ciclo de vida de interação com um banco de dados vetorial. Agora você sabe como:\n",
    "- **Configurar e conectar** a um banco de dados vetorial.\n",
    "- **Criar uma coleção** para armazenar vetores.\n",
    "- **Inserir dados** usando embeddings.\n",
    "- **Realizar buscas** semânticas e com filtros.\n",
    "- **Gerenciar os dados** com operações de busca por ID, deleção e contagem.\n",
    "\n",
    "Com este conhecimento, você está pronto para o próximo e último passo do nosso projeto!\n",
    "\n",
    "### Próximo Passo do Projeto Geral\n",
    "\n",
    "Usar todo esse conhecimento para construir o **caso de uso final**: uma aplicação web interativa com Streamlit, que será o arquivo `src/app.py`. Lá, vamos focar em usar a operação de `search` para criar uma experiência de busca incrível para o usuário.\n",
    "\n",
    "Teste no terminal: **streamlit run src/app.py**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
